# FAQ: Конфигурация и настройка системы Соната-2041

## Вопрос: Какие требования для запуска системы?

**Ответ:**
Для работы системы Соната-2041 необходимо:

**Программное обеспечение:**
- Java 21 или выше
- Gradle (включен в проект через wrapper)
- Ollama с моделями:
  - `nomic-embed-text:latest` (для эмбеддингов)
  - `llama3.1:8b` (для генерации ответов)

**Установка моделей Ollama:**
```bash
ollama pull nomic-embed-text:latest
ollama pull llama3.1:8b
```

**Системные требования:**
- Минимум 8GB RAM (рекомендуется 16GB)
- Минимум 10GB свободного места на диске
- Процессор с поддержкой AVX2 (для Ollama)

## Вопрос: Как настроить подключение к Ollama?

**Ответ:**
По умолчанию система подключается к Ollama по адресу `http://localhost:11434`.

**Изменение адреса:**
Используйте параметр `--ollama-url` в любой команде:

```bash
./gradlew run --args="index /path --ollama-url http://192.168.1.10:11434"
```

**Проверка подключения:**
1. Убедитесь, что Ollama запущен: `ollama list`
2. Проверьте доступность: `curl http://localhost:11434/api/tags`

**Частые проблемы:**
- **Connection refused**: Ollama не запущен или использует другой порт
- **Connection timeout**: Проблема с сетью или файрволом
- **Model not found**: Нужная модель не установлена

## Вопрос: Где хранится база данных?

**Ответ:**
По умолчанию база данных SQLite создается в файле `./index.db` в директории запуска.

**Изменение пути:**
Используйте параметр `--db-path`:

```bash
./gradlew run --args="index /path --db-path /custom/path/index.db"
```

**Важно:** Используйте один и тот же путь во всех командах (index, search, qa, history), иначе команды будут работать с разными базами данных.

## Вопрос: Как настроить производительность?

**Ответ:**
Для оптимизации производительности системы:

**1. Настройка chunk-size:**
- Меньше чанки = больше точность, но медленнее индексация
- Больше чанки = быстрее индексация, но может быть хуже релевантность

**2. Настройка top-k:**
- Меньше результатов = быстрее ответ
- Больше результатов = больше контекста, но медленнее

**3. Реранкинг:**
- Отключен = быстро, но может быть менее точно
- Включен = медленно, но более точно

**4. Настройка JVM:**
Добавьте в `gradle.properties`:
```properties
org.gradle.jvmargs=-Xmx4g -XX:MaxMetaspaceSize=512m
```

**5. Оптимизация Ollama:**
- Используйте GPU если доступно
- Настройте количество потоков в Ollama

## Вопрос: Ошибка подключения к Ollama

**Ответ:**
Если вы получаете ошибку "Failed to connect to Ollama":

**1. Проверьте, что Ollama запущен:**
```bash
ollama list
```

**2. Проверьте порт:**
Ollama по умолчанию использует порт 11434. Проверьте, что порт свободен:
```bash
netstat -an | grep 11434
```

**3. Проверьте файрвол:**
Убедитесь, что порт 11434 открыт в файрволе:
```bash
# Linux (ufw)
sudo ufw allow 11434

# Linux (firewalld)
sudo firewall-cmd --add-port=11434/tcp --permanent
sudo firewall-cmd --reload
```

**4. Проверьте, что модели установлены:**
```bash
ollama list
```
Должны быть установлены `nomic-embed-text:latest` и `llama3.1:8b`.

**5. Проверьте логи Ollama:**
```bash
ollama logs
```

## Вопрос: Как изменить модель LLM?

**Ответ:**
По умолчанию система использует модель `llama3.1:8b`. Для изменения модели необходимо:

1. Установить другую модель через Ollama:
```bash
ollama pull mistral:latest
```

2. Изменить код в файле `OllamaLlmService.kt`:
```kotlin
class OllamaLlmService(
    private val baseUrl: String = "http://localhost:11434",
    private val model: String = "mistral:latest",  // Измените здесь
    private val logFile: Path = Path.of("llm-requests.log")
)
```

3. Пересобрать проект:
```bash
./gradlew build
```

**Рекомендуемые модели:**
- `llama3.1:8b` - хороший баланс качества и скорости (по умолчанию)
- `llama3.1:70b` - лучшее качество, но требует много RAM
- `mistral:latest` - быстрая альтернатива
- `mixtral:8x7b` - хорошее качество, средняя скорость

## Вопрос: Где находятся логи?

**Ответ:**
Система создает следующие логи:

**1. Логи LLM запросов:**
Файл: `llm-requests.log` (в директории запуска)
Содержит все запросы к LLM и ответы.

**2. Логи приложения:**
Gradle выводит логи в консоль. Для сохранения в файл:
```bash
./gradlew run --args="..." 2>&1 | tee app.log
```

**3. Логи Ollama:**
Зависит от вашей системы:
- Linux: `journalctl -u ollama`
- macOS: `~/Library/Logs/Ollama/`
- Docker: `docker logs ollama`

## Вопрос: Как очистить кэш и пересобрать проект?

**Ответ:**
Для чистой пересборки проекта:

```bash
# Очистка сборки
./gradlew clean

# Сборка проекта
./gradlew build

# Или все вместе
./gradlew clean build
```

Для полной очистки включая Gradle кэш:
```bash
./gradlew clean --no-daemon
rm -rf .gradle
./gradlew build
```

## Вопрос: Как настроить регламент хранения данных?

**Ответ:**
В проекте Соната-2041 установлен регламент:

**Базовый срок хранения рабочих индексов:** 90 дней с момента последнего обновления.

**Для автоматической очистки старых данных:**
1. Создайте скрипт очистки
2. Настройте cron (Linux) или Task Scheduler (Windows)
3. Скрипт должен проверять дату последнего обновления документов и удалять старые

**Пример скрипта (bash):**
```bash
#!/bin/bash
# Удаляет индекс если он старше 90 дней
DB_PATH="./index.db"
if [ -f "$DB_PATH" ]; then
    AGE_DAYS=$(( ($(date +%s) - $(stat -c %Y "$DB_PATH")) / 86400 ))
    if [ $AGE_DAYS -gt 90 ]; then
        rm "$DB_PATH"
        echo "Index deleted (age: $AGE_DAYS days)"
    fi
fi
```

## Вопрос: Можно ли использовать систему в Docker?

**Ответ:**
Да, систему можно запустить в Docker. Для этого:

1. Создайте Dockerfile для приложения
2. Используйте Docker Compose для связки с Ollama
3. Пробросьте порты и тома для базы данных

**Пример docker-compose.yml:**
```yaml
services:
  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama

  sonata:
    build: .
    depends_on:
      - ollama
    environment:
      - OLLAMA_URL=http://ollama:11434
    volumes:
      - ./data:/app/data
      - ./index.db:/app/index.db

volumes:
  ollama_data:
```

Этот вопрос находится в разработке для официальной поддержки.
